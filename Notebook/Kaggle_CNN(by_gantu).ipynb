{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3d5937cbbfe21d16ef0de3681410d85a803f93e2"
      },
      "cell_type": "code",
      "source": "from keras.models import *\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom sklearn.model_selection import train_test_split\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport numpy as np\nfrom sklearn.metrics import*\nimport keras.activations\nfrom keras.callbacks import EarlyStopping\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "00a7bd3da23b2ede397ae30f31697b6c2947b878"
      },
      "cell_type": "code",
      "source": "epsilon= 0.000001\nlearning_rate=0.001\nnum_epochs=50\nvalidation_ratio=0.3",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4fd5410e205b006a351af1ccf5d137e800fa9879"
      },
      "cell_type": "code",
      "source": "root=\"../input/mid-brain-images/data/data/\"\nx=[]\ns=[]\nfor i in range(1, 7):\n    x_temp = np.load(root+'x_train'+str(i)+'.npy')\n    s_temp = np.load(root+'s_train'+str(i)+'.npy')\n    x.append(x_temp); s.append(s_temp)\n    ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "04b286dd4a8015cba04da73ac27d5e5086bbc34c"
      },
      "cell_type": "code",
      "source": "for i in range(1, 6):\n    x[0]= np.concatenate((x[0], x[i]))\nfor i in range(1, 6):\n    s[0]= np.concatenate((s[0], s[i]))",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "627a72e42aaf47a28d8cc75abe686782dbd35f2c"
      },
      "cell_type": "code",
      "source": "x_train, x_val, s_train, s_val = train_test_split(x[0],s[0], test_size=0.3, random_state=42)\nmean= np.mean(x_train, axis=0)\nstd = np.std(x_train, axis=0)\nx_train = (x_train-mean)/(std+epsilon)\nx_val = (x_val- mean)/(std+epsilon)\n\nx_train = np.expand_dims(x_train, axis=3)\nx_val = np.expand_dims(x_val, axis=3)\ns_train= np.expand_dims(s_train, axis=1)\ns_val= np.expand_dims(s_val, axis=1)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "943cbd6eebe493d87ce4afe834e9a8ace628406f"
      },
      "cell_type": "code",
      "source": "# def CNN_model(input_shape):\n#     X_input = Input(input_shape)  # 180, 180, 1\n#     out= Conv2D(4, (9, 9),strides= (2, 2))(X_input) #86,86,4\n#     out= MaxPool2D(strides=(1, 1))(out) #85,85,4\n#     out= Activation('relu')(out) #85, 85, 4\n#     out= Conv2D(16, (7, 7),strides=  (2, 2))(out) #40, 40, 16\n#     out= MaxPool2D(strides=(1, 1))(out) #39, 39, 16\n#     out= Activation('relu')(out) \n#     out= Conv2D(32, (5, 5), strides= (2, 2))(out) #18,18 32\n#     out= MaxPool2D(strides=(1, 1))(out) #17, 17, 32\n#     out= Activation('relu')(out) \n#     out= Conv2D(64, (5, 5), activation='relu', strides=(2, 2))(out) #7, 7, 64\n#     out= Flatten()(out)\n#     out= Dense(2048, activation='relu')(out)\n#     out= Dense(1024, activation='relu')(out)\n#     out= Dense(512, activation='relu')(out)\n#     out= Dense(64, activation='relu')(out)\n#     out= Dense(10, activation='relu')(out)\n#     out= Dense(1, activation='sigmoid')(out)\n    \n#     return Model(inputs= X_input, outputs= out)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2ffa35278c6fb80c7191bdd19b842043169249a",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# model= CNN_model((180, 180, 1))\n# model.compile(optimizer='Nadam',loss='binary_crossentropy',metrics=['accuracy'])\n# model.fit(x=x_train, y=s_train, batch_size=64, epochs=30,verbose=True, validation_data=(x_val, s_val))\n# model.save('saved_model.h5')\n# # predictions =model.predict(x_val)\n# from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_curve\n# predictions= predictions>=0.5\n# accuracy_score = accuracy_score(s_val, predictions)\n# recall_score= recall_score(s_val, predictions)\n# f1_score=f1_score(s_val, predictions)\n# print(accuracy_score)\n# print(recall_score)\n# print(f1_score)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52d71854e0b070b1b4f68f48215c617ec8a3ed52"
      },
      "cell_type": "code",
      "source": "#applying batch norm\ndef CNN2_model(input_shape):\n    X_input = Input(input_shape)  # 180, 180, 1\n    out= Conv2D(4, (9, 9),strides= (2, 2))(X_input) #86,86,4\n    out= MaxPool2D(strides=(1, 1))(out) #85,85,4\n    out= Activation('relu')(out) #85, 85, 4\n    out= Conv2D(16, (7, 7),strides=  (2, 2))(out) #40, 40, 16\n    out= MaxPool2D(strides=(1, 1))(out) #39, 39, 16\n    out= Activation('relu')(out) \n    out= Conv2D(32, (5, 5), strides= (2, 2))(out) #18,18 32\n    out= MaxPool2D(strides=(1, 1))(out) #17, 17, 32\n    out= Activation('relu')(out) \n    out= Conv2D(64, (5, 5), activation='relu', strides=(2, 2))(out) #7, 7, 64\n    out= Flatten()(out)\n    out= Dense(2048, activation='relu')(out)\n    out= BatchNormalization()(out)\n    out= Dense(1024, activation='relu')(out)\n    out= BatchNormalization()(out)\n    out= Dense(512, activation='relu')(out)\n    out= BatchNormalization()(out)\n    out= Dense(64, activation='relu')(out)\n    out= BatchNormalization()(out)\n    out= Dense(10, activation='relu')(out)\n    out= Dense(1, activation='sigmoid')(out)\n    \n    return Model(inputs= X_input, outputs= out)\n\n#even more batch size:\n#when trained on more epochs\n\nes = EarlyStopping(monitor='val_loss', mode='min', patience=10,baseline=0.974)\nmodel3= CNN2_model((180, 180, 1))\nmodel3.compile(optimizer='Nadam',loss='binary_crossentropy',metrics=['accuracy'])\nhistory=model3.fit(x=x_train, y=s_train, batch_size=64,callbacks=[es] ,epochs=55,verbose=True, validation_data=(x_val, s_val))\nmodel3.save('saved_model3.h5')\npredictions =model3.predict(x_val)\npredictions= predictions>=0.5\nfrom sklearn.metrics import f1_score, accuracy_score, recall_score, roc_curve\naccuracy_score = accuracy_score(s_val, predictions)\nrecall_score= recall_score(s_val, predictions)\nf1_score=f1_score(s_val, predictions)\nfrom scipy.spatial.distance import dice\ndice_diss_coeff = dice(s_val, predictions)\nDSC= 1-dice_diss_coeff\nprint(\"DSC = \"+str(DSC))\nprint(\"accuracy = \"+str(accuracy_score))\nprint('recall = '+str(recall_score))\nprint('f1 score = '+str(f1_score))\n",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 11503 samples, validate on 4931 samples\nEpoch 1/55\n11503/11503 [==============================] - 15s 1ms/step - loss: 0.4398 - acc: 0.8022 - val_loss: 0.4351 - val_acc: 0.8027\nEpoch 2/55\n11503/11503 [==============================] - 11s 951us/step - loss: 0.3918 - acc: 0.8140 - val_loss: 0.4554 - val_acc: 0.8071\nEpoch 3/55\n11503/11503 [==============================] - 11s 946us/step - loss: 0.3520 - acc: 0.8318 - val_loss: 0.4119 - val_acc: 0.8296\nEpoch 4/55\n11503/11503 [==============================] - 11s 956us/step - loss: 0.2920 - acc: 0.8674 - val_loss: 0.3398 - val_acc: 0.8688\nEpoch 5/55\n11503/11503 [==============================] - 11s 944us/step - loss: 0.2317 - acc: 0.8977 - val_loss: 0.2525 - val_acc: 0.9100\nEpoch 6/55\n11503/11503 [==============================] - 11s 953us/step - loss: 0.1778 - acc: 0.9250 - val_loss: 0.2303 - val_acc: 0.9140\nEpoch 7/55\n11503/11503 [==============================] - 11s 948us/step - loss: 0.1439 - acc: 0.9403 - val_loss: 0.2733 - val_acc: 0.8980\nEpoch 8/55\n11503/11503 [==============================] - 11s 949us/step - loss: 0.1226 - acc: 0.9519 - val_loss: 0.2530 - val_acc: 0.9108\nEpoch 9/55\n11503/11503 [==============================] - 11s 946us/step - loss: 0.1070 - acc: 0.9580 - val_loss: 0.1880 - val_acc: 0.9383\nEpoch 10/55\n11503/11503 [==============================] - 11s 950us/step - loss: 0.0860 - acc: 0.9666 - val_loss: 0.1899 - val_acc: 0.9440\nEpoch 11/55\n11503/11503 [==============================] - 11s 952us/step - loss: 0.0803 - acc: 0.9704 - val_loss: 0.1264 - val_acc: 0.9621\nEpoch 12/55\n11503/11503 [==============================] - 11s 944us/step - loss: 0.0662 - acc: 0.9751 - val_loss: 0.1642 - val_acc: 0.9556\nEpoch 13/55\n11503/11503 [==============================] - 11s 953us/step - loss: 0.0666 - acc: 0.9737 - val_loss: 0.1318 - val_acc: 0.9627\nEpoch 14/55\n11503/11503 [==============================] - 11s 944us/step - loss: 0.0687 - acc: 0.9741 - val_loss: 0.1158 - val_acc: 0.9671\nEpoch 15/55\n11503/11503 [==============================] - 11s 953us/step - loss: 0.0616 - acc: 0.9767 - val_loss: 0.1203 - val_acc: 0.9680\nEpoch 16/55\n11503/11503 [==============================] - 11s 944us/step - loss: 0.0680 - acc: 0.9754 - val_loss: 0.1281 - val_acc: 0.9617\nEpoch 17/55\n11503/11503 [==============================] - 11s 956us/step - loss: 0.0577 - acc: 0.9780 - val_loss: 0.1380 - val_acc: 0.9600\nEpoch 18/55\n11503/11503 [==============================] - 11s 946us/step - loss: 0.0475 - acc: 0.9820 - val_loss: 0.1335 - val_acc: 0.9659\nEpoch 19/55\n11503/11503 [==============================] - 11s 955us/step - loss: 0.0486 - acc: 0.9814 - val_loss: 0.2584 - val_acc: 0.9004\nEpoch 20/55\n11503/11503 [==============================] - 11s 941us/step - loss: 0.0544 - acc: 0.9787 - val_loss: 0.1150 - val_acc: 0.9718\nEpoch 21/55\n11503/11503 [==============================] - 11s 951us/step - loss: 0.0370 - acc: 0.9871 - val_loss: 0.1244 - val_acc: 0.9710\nEpoch 22/55\n11503/11503 [==============================] - 11s 939us/step - loss: 0.0389 - acc: 0.9864 - val_loss: 0.1249 - val_acc: 0.9688\nEpoch 23/55\n11503/11503 [==============================] - 11s 951us/step - loss: 0.0296 - acc: 0.9897 - val_loss: 0.1632 - val_acc: 0.9507\nEpoch 24/55\n11503/11503 [==============================] - 11s 940us/step - loss: 0.0677 - acc: 0.9747 - val_loss: 0.1268 - val_acc: 0.9645\nEpoch 25/55\n11503/11503 [==============================] - 11s 950us/step - loss: 0.0378 - acc: 0.9851 - val_loss: 0.1316 - val_acc: 0.9661\nEpoch 26/55\n11503/11503 [==============================] - 11s 947us/step - loss: 0.0310 - acc: 0.9898 - val_loss: 0.1055 - val_acc: 0.9753\nEpoch 27/55\n11503/11503 [==============================] - 11s 947us/step - loss: 0.0219 - acc: 0.9923 - val_loss: 0.0935 - val_acc: 0.9781\nEpoch 28/55\n11503/11503 [==============================] - 11s 947us/step - loss: 0.0327 - acc: 0.9884 - val_loss: 0.1812 - val_acc: 0.9412\nEpoch 29/55\n11503/11503 [==============================] - 11s 958us/step - loss: 0.0677 - acc: 0.9732 - val_loss: 0.1359 - val_acc: 0.9665\nEpoch 30/55\n11503/11503 [==============================] - 11s 943us/step - loss: 0.0410 - acc: 0.9855 - val_loss: 0.1193 - val_acc: 0.9716\nEpoch 31/55\n11503/11503 [==============================] - 11s 943us/step - loss: 0.0433 - acc: 0.9849 - val_loss: 0.1289 - val_acc: 0.9680\nEpoch 32/55\n11503/11503 [==============================] - 11s 955us/step - loss: 0.0262 - acc: 0.9912 - val_loss: 0.1125 - val_acc: 0.9747\nEpoch 33/55\n11503/11503 [==============================] - 11s 946us/step - loss: 0.0265 - acc: 0.9897 - val_loss: 0.1351 - val_acc: 0.9694\nEpoch 34/55\n11503/11503 [==============================] - 11s 955us/step - loss: 0.0260 - acc: 0.9902 - val_loss: 0.0984 - val_acc: 0.9767\nEpoch 35/55\n11503/11503 [==============================] - 11s 952us/step - loss: 0.0191 - acc: 0.9926 - val_loss: 0.1060 - val_acc: 0.9722\nEpoch 36/55\n11503/11503 [==============================] - 11s 947us/step - loss: 0.0212 - acc: 0.9932 - val_loss: 0.0816 - val_acc: 0.9783\nEpoch 37/55\n11503/11503 [==============================] - 11s 955us/step - loss: 0.0195 - acc: 0.9944 - val_loss: 0.0824 - val_acc: 0.9789\nEpoch 38/55\n11503/11503 [==============================] - 11s 947us/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.0922 - val_acc: 0.9783\nEpoch 39/55\n11503/11503 [==============================] - 11s 954us/step - loss: 0.0200 - acc: 0.9932 - val_loss: 0.0879 - val_acc: 0.9765\nEpoch 40/55\n11503/11503 [==============================] - 11s 944us/step - loss: 0.0182 - acc: 0.9930 - val_loss: 0.0971 - val_acc: 0.9728\nEpoch 41/55\n11503/11503 [==============================] - 11s 944us/step - loss: 0.0193 - acc: 0.9928 - val_loss: 0.1016 - val_acc: 0.9749\nEpoch 42/55\n11503/11503 [==============================] - 11s 954us/step - loss: 0.0222 - acc: 0.9922 - val_loss: 0.0913 - val_acc: 0.9785\nEpoch 43/55\n11503/11503 [==============================] - 11s 943us/step - loss: 0.0207 - acc: 0.9938 - val_loss: 0.1097 - val_acc: 0.9744\nEpoch 44/55\n11503/11503 [==============================] - 11s 953us/step - loss: 0.0217 - acc: 0.9928 - val_loss: 0.1083 - val_acc: 0.9742\nEpoch 45/55\n11503/11503 [==============================] - 11s 944us/step - loss: 0.0212 - acc: 0.9920 - val_loss: 0.0887 - val_acc: 0.9781\nEpoch 46/55\n11503/11503 [==============================] - 11s 949us/step - loss: 0.0281 - acc: 0.9901 - val_loss: 0.1025 - val_acc: 0.9732\n",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'float' object cannot be interpreted as an integer",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c8a08d2ac3aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mDSC\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdice_diss_coeff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdirected_hausdorff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdirected_hausdorff\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirected_hausdorff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirected_hausdorff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hausdorff distance = \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirected_hausdorff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DSC = \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDSC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2503\u001b[0m     \"\"\"\n\u001b[1;32m   2504\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2505\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fafe24d9fc3bb3f3a038c1a740738c15aab104b1",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from scipy.spatial.distance import dice\ndice_diss_coeff = dice(s_val, predictions)\nDSC= 1-dice_diss_coeff\nprint(DSC)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.9835575485799701\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0c262ae04f1e38dafd77d00947e43c99a0c2de6b"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, color='red', label='Training loss')\nplt.plot(epochs, val_loss, color='green', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "36bbba8311c33b88f25697782812ef2dd30c5612"
      },
      "cell_type": "code",
      "source": "acc = history.history['acc']\nval_acc = history.history['val_acc']\nplt.plot(epochs, acc, color='red', label='Training acc')\nplt.plot(epochs, val_acc, color='green', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a47f9683dc7143d9e8817782b0c120c10a144caf"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}